---
title: "An Empirical Study of Modular Bias Mitigators and Ensembles (short version)"
collection: publications
permalink: /publication/2022-07-22-empirical-study-short-version
excerpt: 'Bias mitigators can reduce algorithmic bias in machine learning models, but their effect on fairness is often not stable across different data splits. A popular approach to train more stable models is ensemble learning. We built an open-source library enabling the modular composition of 10 mitigators, 4 ensembles, and their corresponding hyperparameters. We empirically explored the space of combinations on 13 datasets and distilled the results into a guidance diagram for practitioners.'
date: 2022-07-22
venue: 'Workshop on Benchmarking Data for Data-Centric AI (DataPerf@ICML)'
paperurl: 'http://hirzels.com/martin/papers/dataperf22-fair-ensembles.pdf'
citation: 'Michael Feffer, Martin Hirzel, Samuel C. Hoffman, Kiran Kate, Parikshit Ram, and Avraham Shinnar. An Empirical Study of Modular Bias Mitigators and Ensembles. Workshop on Benchmarking Data for Data-Centric AI (DataPerf@ICML), July 2022.'
---

<a href='http://hirzels.com/martin/papers/dataperf22-fair-ensembles.pdf'>Download paper here</a>

Bias mitigators can reduce algorithmic bias in machine learning models, but their effect on fairness is often not stable across different data splits. A popular approach to train more stable models is ensemble learning. We built an open-source library enabling the modular composition of 10 mitigators, 4 ensembles, and their corresponding hyperparameters. We empirically explored the space of combinations on 13 datasets and distilled the results into a guidance diagram for practitioners.

Recommended citation: Michael Feffer, Martin Hirzel, Samuel C. Hoffman, Kiran Kate, Parikshit Ram, and Avraham Shinnar. An Empirical Study of Modular Bias Mitigators and Ensembles. Workshop on Benchmarking Data for Data-Centric AI (DataPerf@ICML), July 2022.