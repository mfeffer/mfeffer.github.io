pub_date	title	venue	excerpt	citation	url_slug	paper_url
2018-06-08	Personalized machine learning for facial expression analysis	MIT EECS Department	"For this MEng Thesis Project, I investigated the personalization of deep convolutional networks for facial expression analysis."	"Feffer, Michael Anthony. Personalized machine learning for facial expression analysis. MEng Thesis. Massachusetts Institute of Technology, 2018."	personalized-machine-learning	https://dspace.mit.edu/bitstream/handle/1721.1/119763/1078783584-MIT.pdf?sequence=1&isAllowed=y
2018-07-15	A Mixture of Personalized Experts for Human Affect Estimation	MLDM	"We investigate the personalization of deep convolutional neural networks for facial expression analysis from still images. While prior work has focused on population-based (“one-size-fits-all”) approaches, we formulate and construct personalized models via a mixture of experts and supervised domain adaptation approach, showing that it improves greatly upon non-personalized models."	"Feffer M., Rudovic O.., Picard R.W. (2018) A Mixture of Personalized Experts for Human Affect Estimation. In: Perner P. (eds) Machine Learning and Data Mining in Pattern Recognition. MLDM 2018. Lecture Notes in Computer Science, vol 10935. Springer, Cham."	mixture-of-experts	https://dspace.mit.edu/bitstream/handle/1721.1/129494/personalized-mixture-supervised_final_tYWcW0Y.pdf?sequence=2&isAllowed=y
2022-02-01	An Empirical Study of Modular Bias Mitigators and Ensembles (long version)	arxiv	"There are several bias mitigators that can reduce algorithmic bias in machine learning models but, unfortunately, the effect of mitigators on fairness is often not stable when measured across different data splits. A popular approach to train more stable models is ensemble learning. Ensembles, such as bagging, boosting, voting, or stacking, have been successful at making predictive performance more stable. One might therefore ask whether we can combine the advantages of bias mitigators and ensembles? To explore this question, we first need bias mitigators and ensembles to work together. We built an open-source library enabling the modular composition of 10 mitigators, 4 ensembles, and their corresponding hyperparameters. Based on this library, we empirically explored the space of combinations on 13 datasets, including datasets commonly used in fairness literature plus datasets newly curated by our library. Furthermore, we distilled the results into a guidance diagram for practitioners. We hope this paper will contribute towards improving stability in bias mitigation."	"Michael Feffer, Martin Hirzel, Samuel C. Hoffman, Kiran Kate, Parikshit Ram, and Avraham Shinnar. An Empirical Study of Modular Bias Mitigators and Ensembles. arXiv:2202.00751 [cs.LG], February 2022."	empirical-study-long-version	https://arxiv.org/pdf/2202.00751.pdf
2022-07-22	An Empirical Study of Modular Bias Mitigators and Ensembles (short version)	Workshop on Benchmarking Data for Data-Centric AI (DataPerf@ICML)	"Bias mitigators can reduce algorithmic bias in machine learning models, but their effect on fairness is often not stable across different data splits. A popular approach to train more stable models is ensemble learning. We built an open-source library enabling the modular composition of 10 mitigators, 4 ensembles, and their corresponding hyperparameters. We empirically explored the space of combinations on 13 datasets and distilled the results into a guidance diagram for practitioners."	"Michael Feffer, Martin Hirzel, Samuel C. Hoffman, Kiran Kate, Parikshit Ram, and Avraham Shinnar. An Empirical Study of Modular Bias Mitigators and Ensembles. Workshop on Benchmarking Data for Data-Centric AI (DataPerf@ICML), July 2022."	empirical-study-short-version	http://hirzels.com/martin/papers/dataperf22-fair-ensembles.pdf
